{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bbf85495",
      "metadata": {},
      "source": [
        "# Donor Compass Colab Demo (Standalone)\n",
        "\n",
        "This notebook is a standalone snapshot demo of the Donor Compass allocation library.\n",
        "\n",
        "## What this notebook includes\n",
        "- Core calculator and allocation functions\n",
        "- All aggregation methods currently supported in `donor_compass.py`\n",
        "- A simple demo runner for one method or all methods\n",
        "- Two plain-language validation checks:\n",
        "  - **Check 1: Dominant Then Saturating Project**\n",
        "  - **Check 2: Same Credences Across Methods**\n",
        "\n",
        "## Quick start for first-time users\n",
        "1. Run the dependency/setup cell.\n",
        "2. Run the standalone implementation cell.\n",
        "3. Run the single-method demo cells.\n",
        "4. Run the all-method comparison cell.\n",
        "5. Run the validation checks cell at the end.\n",
        "\n",
        "## Important notes\n",
        "- This notebook is intentionally self-contained (no local file imports required).\n",
        "- Source of truth is still the Python files in the repository (`donor_compass.py`, `met_sim_utils.py`, `multi_stage_aggregation.py`).\n",
        "- If running in Colab, run cells from top to bottom (or use **Runtime -> Run all**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "65dae4dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not running in Colab - skipping install cell.\n"
          ]
        }
      ],
      "source": [
        "# Colab dependency setup\n",
        "# This installs required packages only when running in Colab.\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Running in Colab - installing dependencies...\")\n",
        "    subprocess.check_call(\n",
        "        [\n",
        "            sys.executable,\n",
        "            \"-m\",\n",
        "            \"pip\",\n",
        "            \"install\",\n",
        "            \"-q\",\n",
        "            \"numpy\",\n",
        "            \"scipy\",\n",
        "            \"scikit-learn\",\n",
        "            \"pandas\",\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    print(\"Not running in Colab - skipping install cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "829b5ad1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded standalone Donor Compass snapshot.\n",
            "Available methods: ['credence_weighted', 'my_favorite_theory', 'mec', 'met', 'nash_bargaining', 'msa', 'borda', 'split_cycle', 'lexicographic_maximin']\n"
          ]
        }
      ],
      "source": [
        "# Standalone Donor Compass implementation snapshot\n",
        "# Copied/adapted from donor_compass.py, met_sim_utils.py, and multi_stage_aggregation.py\n",
        "\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Demo data presets\n",
        "# -----------------------------------------------------------------------------\n",
        "DEFAULT_PROJECT_DATA = {\n",
        "    \"project_human\": {\n",
        "        \"tags\": {\"near_term_xrisk\": False},\n",
        "        \"diminishing_returns\": [\n",
        "            1.0, 0.8, 0.6, 0.45, 0.35, 0.28, 0.22, 0.18, 0.15, 0.12,\n",
        "            0.10, 0.09, 0.08, 0.07, 0.06,\n",
        "        ],\n",
        "        \"effects\": {\n",
        "            \"effect_human\": {\n",
        "                \"recipient_type\": \"human_life_years\",\n",
        "                \"values\": [\n",
        "                    [220, 240, 180, 200],\n",
        "                    [200, 220, 170, 185],\n",
        "                    [180, 195, 160, 170],\n",
        "                    [150, 160, 140, 145],\n",
        "                    [100, 110, 90, 95],\n",
        "                    [80, 85, 70, 75],\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "    \"project_chicken\": {\n",
        "        \"tags\": {\"near_term_xrisk\": False},\n",
        "        \"diminishing_returns\": [\n",
        "            1.0, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55,\n",
        "            0.50, 0.46, 0.42, 0.38, 0.34,\n",
        "        ],\n",
        "        \"effects\": {\n",
        "            \"effect_chicken\": {\n",
        "                \"recipient_type\": \"chickens_birds\",\n",
        "                \"values\": [\n",
        "                    [180, 190, 150, 170],\n",
        "                    [170, 180, 145, 160],\n",
        "                    [160, 170, 140, 155],\n",
        "                    [140, 150, 130, 140],\n",
        "                    [120, 130, 110, 120],\n",
        "                    [100, 110, 95, 100],\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "    \"project_fish\": {\n",
        "        \"tags\": {\"near_term_xrisk\": False},\n",
        "        \"diminishing_returns\": [\n",
        "            1.0, 0.96, 0.92, 0.88, 0.84, 0.80, 0.76, 0.72, 0.68, 0.64,\n",
        "            0.60, 0.56, 0.52, 0.48, 0.44,\n",
        "        ],\n",
        "        \"effects\": {\n",
        "            \"effect_fish\": {\n",
        "                \"recipient_type\": \"fish\",\n",
        "                \"values\": [\n",
        "                    [140, 150, 120, 130],\n",
        "                    [135, 145, 115, 125],\n",
        "                    [130, 140, 110, 120],\n",
        "                    [120, 130, 105, 115],\n",
        "                    [110, 120, 95, 105],\n",
        "                    [100, 110, 90, 100],\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "EXAMPLE_CUSTOM_WORLDVIEWS = [\n",
        "    {\n",
        "        \"name\": \"HumanAnchor\",\n",
        "        \"credence\": 0.5,\n",
        "        \"moral_weights\": {\n",
        "            \"human_life_years\": 1.0,\n",
        "            \"human_ylds\": 0.4,\n",
        "            \"human_income_doublings\": 0.2,\n",
        "            \"chickens_birds\": 0.1,\n",
        "            \"fish\": 0.05,\n",
        "            \"shrimp\": 0.0,\n",
        "            \"non_shrimp_invertebrates\": 0.0,\n",
        "            \"mammals\": 0.05,\n",
        "        },\n",
        "        \"discount_factors\": [1.0, 0.95, 0.8, 0.6, 0.4, 0.3],\n",
        "        \"risk_profile\": 0,\n",
        "        \"p_extinction\": 0.05,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"ChickenAnchor\",\n",
        "        \"credence\": 0.3,\n",
        "        \"moral_weights\": {\n",
        "            \"human_life_years\": 0.1,\n",
        "            \"human_ylds\": 0.2,\n",
        "            \"human_income_doublings\": 0.1,\n",
        "            \"chickens_birds\": 1.0,\n",
        "            \"fish\": 0.2,\n",
        "            \"shrimp\": 0.0,\n",
        "            \"non_shrimp_invertebrates\": 0.0,\n",
        "            \"mammals\": 0.2,\n",
        "        },\n",
        "        \"discount_factors\": [1.0, 0.95, 0.8, 0.6, 0.4, 0.3],\n",
        "        \"risk_profile\": 0,\n",
        "        \"p_extinction\": 0.05,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"FishAnchor\",\n",
        "        \"credence\": 0.2,\n",
        "        \"moral_weights\": {\n",
        "            \"human_life_years\": 0.1,\n",
        "            \"human_ylds\": 0.2,\n",
        "            \"human_income_doublings\": 0.1,\n",
        "            \"chickens_birds\": 0.1,\n",
        "            \"fish\": 1.0,\n",
        "            \"shrimp\": 0.0,\n",
        "            \"non_shrimp_invertebrates\": 0.0,\n",
        "            \"mammals\": 0.1,\n",
        "        },\n",
        "        \"discount_factors\": [1.0, 0.95, 0.8, 0.6, 0.4, 0.3],\n",
        "        \"risk_profile\": 0,\n",
        "        \"p_extinction\": 0.05,\n",
        "    },\n",
        "]\n",
        "\n",
        "INCREMENT_SIZE = 10\n",
        "AGGREGATION_DEFAULTS = {\n",
        "    \"met_threshold\": 0.50,\n",
        "    \"nash_disagreement_point\": \"zero_spending\",\n",
        "    \"msa_permissibility_mode\": \"winner_take_all\",\n",
        "    \"msa_top_k\": 2,\n",
        "    \"msa_within_percent\": 0.10,\n",
        "    \"msa_binary_threshold\": 0.0,\n",
        "    \"tie_break\": \"deterministic\",\n",
        "}\n",
        "MSA_DEFAULT_BINARY_WORLDVIEWS = {\"Kantianism\", \"Rawlsian Contractarianism\"}\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Calculator functions\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_single_effect(effect_data, moral_weight, discount_factors, risk_profile):\n",
        "    values_matrix = np.array(effect_data[\"values\"], dtype=float)\n",
        "    r_etq = values_matrix[:, int(risk_profile)]\n",
        "    D_t = np.array(discount_factors, dtype=float)\n",
        "    return float(moral_weight * np.sum(r_etq * D_t))\n",
        "\n",
        "\n",
        "def calculate_project(project_data, moral_weights, discount_factors, risk_profile):\n",
        "    total = 0.0\n",
        "    breakdown = {}\n",
        "    for effect_id, effect_data in project_data[\"effects\"].items():\n",
        "        m_i = moral_weights.get(effect_data[\"recipient_type\"], 0.0)\n",
        "        value = calculate_single_effect(effect_data, m_i, discount_factors, risk_profile)\n",
        "        breakdown[effect_id] = value\n",
        "        total += value\n",
        "    return {\"total\": float(total), \"breakdown\": breakdown}\n",
        "\n",
        "\n",
        "def calculate_all_projects(data, moral_weights, discount_factors, risk_profile):\n",
        "    results = {}\n",
        "    for project_id, project_data in data.items():\n",
        "        results[project_id] = calculate_project(\n",
        "            project_data, moral_weights, discount_factors, risk_profile\n",
        "        )[\"total\"]\n",
        "    return results\n",
        "\n",
        "\n",
        "def adjust_for_extinction_risk(project_values, data, p_extinction):\n",
        "    adjusted = {}\n",
        "    for project_id, value in project_values.items():\n",
        "        if data[project_id][\"tags\"][\"near_term_xrisk\"]:\n",
        "            adjusted[project_id] = value\n",
        "        else:\n",
        "            adjusted[project_id] = value * (1 - p_extinction)\n",
        "    return adjusted\n",
        "\n",
        "\n",
        "def get_diminishing_returns_factor(data, project_id, current_funding):\n",
        "    step_size = 10.0\n",
        "    steps = float(current_funding) / step_size\n",
        "    nearest_step = int(round(steps))\n",
        "    if np.isclose(steps, nearest_step, atol=1e-9):\n",
        "        idx = nearest_step\n",
        "    else:\n",
        "        idx = int(np.floor(steps))\n",
        "    idx = max(idx, 0)\n",
        "\n",
        "    dr_array = data[project_id][\"diminishing_returns\"]\n",
        "    if idx >= len(dr_array):\n",
        "        return dr_array[-1]\n",
        "    return dr_array[idx]\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Shared voting helpers\n",
        "# -----------------------------------------------------------------------------\n",
        "def _build_rng(tie_break, random_seed):\n",
        "    if tie_break == \"random\":\n",
        "        return random.Random(random_seed)\n",
        "    return None\n",
        "\n",
        "\n",
        "def _choose_from_candidates(candidates, tie_break=\"deterministic\", rng=None):\n",
        "    if not candidates:\n",
        "        raise ValueError(\"No candidates provided.\")\n",
        "    if tie_break == \"random\":\n",
        "        if rng is None:\n",
        "            rng = random.Random()\n",
        "        return rng.choice(list(candidates))\n",
        "    return sorted(candidates)[0]\n",
        "\n",
        "\n",
        "def _argmax_project(scores, tie_break=\"deterministic\", rng=None):\n",
        "    best_value = max(scores.values())\n",
        "    candidates = [p for p, v in scores.items() if np.isclose(v, best_value)]\n",
        "    return _choose_from_candidates(candidates, tie_break=tie_break, rng=rng)\n",
        "\n",
        "\n",
        "def _extract_and_validate_credences(custom_worldviews, require_sum_to_one=False, tolerance=1e-6):\n",
        "    credences = []\n",
        "    for idx, worldview in enumerate(custom_worldviews):\n",
        "        if \"credence\" not in worldview:\n",
        "            raise ValueError(f\"Worldview at index {idx} is missing 'credence'.\")\n",
        "        credence = float(worldview[\"credence\"])\n",
        "        if credence < 0:\n",
        "            name = worldview.get(\"name\", f\"worldview_{idx}\")\n",
        "            raise ValueError(f\"Credence for worldview '{name}' must be non-negative.\")\n",
        "        credences.append(credence)\n",
        "\n",
        "    total = float(sum(credences))\n",
        "    if require_sum_to_one and not np.isclose(total, 1.0, atol=tolerance):\n",
        "        raise ValueError(f\"Worldview credences must sum to 1.0. Got {total:.12f}.\")\n",
        "\n",
        "    return credences, total\n",
        "\n",
        "\n",
        "def _normalize_credences(custom_worldviews):\n",
        "    credences, total = _extract_and_validate_credences(custom_worldviews, require_sum_to_one=False)\n",
        "    if total <= 0:\n",
        "        return [0.0 for _ in credences]\n",
        "    return [c / total for c in credences]\n",
        "\n",
        "\n",
        "def _compute_worldview_marginal_values(data, funding, worldview):\n",
        "    base_values = calculate_all_projects(\n",
        "        data,\n",
        "        worldview[\"moral_weights\"],\n",
        "        worldview[\"discount_factors\"],\n",
        "        worldview[\"risk_profile\"],\n",
        "    )\n",
        "    adjusted_values = adjust_for_extinction_risk(base_values, data, worldview[\"p_extinction\"])\n",
        "    return {\n",
        "        project_id: adjusted_values[project_id]\n",
        "        * get_diminishing_returns_factor(data, project_id, funding[project_id])\n",
        "        for project_id in data\n",
        "    }\n",
        "\n",
        "\n",
        "def _compute_all_worldview_marginal_values(data, funding, custom_worldviews):\n",
        "    return [_compute_worldview_marginal_values(data, funding, worldview) for worldview in custom_worldviews]\n",
        "\n",
        "\n",
        "def _build_project_ranking(project_scores):\n",
        "    return sorted(project_scores.keys(), key=lambda p: (-project_scores[p], p))\n",
        "\n",
        "\n",
        "def _resolve_msa_worldview_type(worldview, worldview_types=None):\n",
        "    explicit = str(worldview.get(\"theory_type\", \"\")).strip().lower()\n",
        "    if explicit in {\"binary\", \"cardinal\"}:\n",
        "        return explicit\n",
        "\n",
        "    name = worldview.get(\"name\", \"\")\n",
        "    if worldview_types and name in worldview_types:\n",
        "        mapped = str(worldview_types[name]).strip().lower()\n",
        "        if mapped in {\"binary\", \"cardinal\"}:\n",
        "            return mapped\n",
        "\n",
        "    if name in MSA_DEFAULT_BINARY_WORLDVIEWS:\n",
        "        return \"binary\"\n",
        "    return \"cardinal\"\n",
        "\n",
        "\n",
        "def _hhi(funding):\n",
        "    total = sum(funding.values())\n",
        "    if total <= 0:\n",
        "        return 0.0\n",
        "    shares = [amount / total for amount in funding.values()]\n",
        "    return float(sum(share * share for share in shares))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MET similarity helpers (adapted from met_sim_utils.py)\n",
        "# -----------------------------------------------------------------------------\n",
        "def calculate_pairwise_similarities(worldviews, projects):\n",
        "    n_worldviews = len(worldviews)\n",
        "    pearson_matrix = np.zeros((n_worldviews, n_worldviews))\n",
        "    rank_matrix = np.zeros((n_worldviews, n_worldviews))\n",
        "\n",
        "    for i, worldview_i in enumerate(worldviews):\n",
        "        for j, worldview_j in enumerate(worldviews):\n",
        "            if i == j:\n",
        "                pearson_matrix[i, j] = 1.0\n",
        "                rank_matrix[i, j] = 1.0\n",
        "            else:\n",
        "                values_i = [worldview_i.evaluate(project) for project in projects]\n",
        "                values_j = [worldview_j.evaluate(project) for project in projects]\n",
        "\n",
        "                if len(set(values_i)) <= 1 or len(set(values_j)) <= 1:\n",
        "                    pearson_corr = 0.0\n",
        "                else:\n",
        "                    pearson_corr, _ = pearsonr(values_i, values_j)\n",
        "                    if np.isnan(pearson_corr):\n",
        "                        pearson_corr = 0.0\n",
        "                pearson_matrix[i, j] = (pearson_corr + 1) / 2\n",
        "\n",
        "                rank_corr, _ = spearmanr(values_i, values_j)\n",
        "                if np.isnan(rank_corr):\n",
        "                    rank_corr = 0.0\n",
        "                rank_matrix[i, j] = (rank_corr + 1) / 2\n",
        "\n",
        "    return pearson_matrix, rank_matrix\n",
        "\n",
        "\n",
        "def embed_worldviews_in_2d_space(pearson_matrix, rank_matrix):\n",
        "    n_worldviews = pearson_matrix.shape[0]\n",
        "    if n_worldviews == 1:\n",
        "        return np.array([[0.0, 0.0]])\n",
        "\n",
        "    distance_matrix = np.zeros((n_worldviews, n_worldviews))\n",
        "    for i in range(n_worldviews):\n",
        "        for j in range(n_worldviews):\n",
        "            pearson_dist = 1 - pearson_matrix[i, j]\n",
        "            rank_dist = 1 - rank_matrix[i, j]\n",
        "            distance_matrix[i, j] = np.sqrt(pearson_dist**2 + rank_dist**2)\n",
        "\n",
        "    mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
        "    positions = mds.fit_transform(distance_matrix)\n",
        "    return positions\n",
        "\n",
        "\n",
        "def calculate_weighted_centroid(positions, weights):\n",
        "    if np.sum(weights) == 0:\n",
        "        return np.array([0.0, 0.0])\n",
        "    return np.average(positions, axis=0, weights=weights)\n",
        "\n",
        "\n",
        "def find_closest_worldview(worldview_positions, target_point):\n",
        "    distances = [euclidean(pos, target_point) for pos in worldview_positions]\n",
        "    return int(np.argmin(distances))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MSA helpers (adapted from multi_stage_aggregation.py)\n",
        "# -----------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class MoralTheory:\n",
        "    name: str\n",
        "    intervention_values: Dict[str, float]\n",
        "\n",
        "    def value_of(self, intervention: str) -> float:\n",
        "        return float(self.intervention_values.get(intervention, 0.0))\n",
        "\n",
        "\n",
        "def mec_aggregate_cardinal_theories(interventions, cardinal_theories, credence_distribution):\n",
        "    if not interventions:\n",
        "        raise ValueError(\"interventions must not be empty\")\n",
        "\n",
        "    intervention_scores = {}\n",
        "    for intervention in interventions:\n",
        "        score = 0.0\n",
        "        for theory in cardinal_theories:\n",
        "            score += credence_distribution.get(theory.name, 0.0) * theory.value_of(intervention)\n",
        "        intervention_scores[intervention] = score\n",
        "\n",
        "    best_intervention = max(interventions, key=lambda i: intervention_scores[i])\n",
        "    return best_intervention, intervention_scores\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Voting methods\n",
        "# -----------------------------------------------------------------------------\n",
        "def vote_credence_weighted_custom(data, funding, increment, custom_worldviews):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    credences, total_credence = _extract_and_validate_credences(custom_worldviews, require_sum_to_one=False)\n",
        "\n",
        "    if not (\n",
        "        np.isclose(total_credence, 1.0, atol=1e-6)\n",
        "        or np.isclose(total_credence, 0.0, atol=1e-12)\n",
        "    ):\n",
        "        raise ValueError(f\"Worldview credences must sum to 1.0 (or all zero). Got {total_credence:.12f}.\")\n",
        "\n",
        "    if np.isclose(total_credence, 0.0, atol=1e-12):\n",
        "        return allocations\n",
        "\n",
        "    rng = _build_rng(AGGREGATION_DEFAULTS[\"tie_break\"], None)\n",
        "    for worldview, credence in zip(custom_worldviews, credences):\n",
        "        share = credence * increment\n",
        "        marginal_values = _compute_worldview_marginal_values(data, funding, worldview)\n",
        "        best_project = _argmax_project(marginal_values, tie_break=\"deterministic\", rng=rng)\n",
        "        allocations[best_project] += share\n",
        "\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_my_favorite_theory(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    results=None,\n",
        "    worldviews=None,\n",
        "    custom_worldviews=None,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "\n",
        "    if custom_worldviews is not None:\n",
        "        if not custom_worldviews:\n",
        "            return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "        credences = _normalize_credences(custom_worldviews)\n",
        "        if np.isclose(sum(credences), 0.0):\n",
        "            return (allocations, {\"strategy\": \"no_positive_credence\"}) if return_debug else allocations\n",
        "\n",
        "        best_idx = int(np.argmax(credences))\n",
        "        selected_worldview = custom_worldviews[best_idx]\n",
        "        marginal_values = _compute_worldview_marginal_values(data, funding, selected_worldview)\n",
        "        best_project = _argmax_project(marginal_values, tie_break=tie_break, rng=rng)\n",
        "        allocations[best_project] = increment\n",
        "\n",
        "        if return_debug:\n",
        "            return allocations, {\n",
        "                \"strategy\": \"custom_worldviews\",\n",
        "                \"selected_worldview\": selected_worldview.get(\"name\", f\"worldview_{best_idx}\"),\n",
        "                \"selected_project\": best_project,\n",
        "            }\n",
        "        return allocations\n",
        "\n",
        "    if worldviews is None or results is None:\n",
        "        raise ValueError(\n",
        "            \"vote_my_favorite_theory requires either custom_worldviews or legacy results + worldviews.\"\n",
        "        )\n",
        "\n",
        "    if not worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    best_wv = max(worldviews, key=lambda worldview: worldview[\"credence\"])\n",
        "    base_values = results[best_wv[\"result_idx\"]][\"project_values\"]\n",
        "    marginal_values = {\n",
        "        project_id: base_values[project_id]\n",
        "        * get_diminishing_returns_factor(data, project_id, funding[project_id])\n",
        "        for project_id in data\n",
        "    }\n",
        "    best_project = _argmax_project(marginal_values, tie_break=tie_break, rng=rng)\n",
        "    allocations[best_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\n",
        "            \"strategy\": \"legacy_precomputed\",\n",
        "            \"selected_worldview\": best_wv.get(\"name\", \"legacy_worldview\"),\n",
        "            \"selected_project\": best_project,\n",
        "        }\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_mec(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    q1_cred=None,\n",
        "    q2_cred=None,\n",
        "    q3_cred=None,\n",
        "    q4_cred=None,\n",
        "    q5_cred=None,\n",
        "    q6_cred=None,\n",
        "    q7_cred=None,\n",
        "    q1_daly_weights=None,\n",
        "    q2_income_weights=None,\n",
        "    q3_chicken_multipliers=None,\n",
        "    q4_shrimp_multipliers=None,\n",
        "    q5_discount_factors=None,\n",
        "    q7_extinction_probs=None,\n",
        "    build_moral_weights_fn=None,\n",
        "    custom_worldviews=None,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "\n",
        "    if custom_worldviews is not None:\n",
        "        if not custom_worldviews:\n",
        "            return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "        credences = _normalize_credences(custom_worldviews)\n",
        "        if np.isclose(sum(credences), 0.0):\n",
        "            return (allocations, {\"strategy\": \"no_positive_credence\"}) if return_debug else allocations\n",
        "\n",
        "        worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "        expected_scores = {\n",
        "            project_id: sum(\n",
        "                credences[idx] * worldview_scores[idx][project_id]\n",
        "                for idx in range(len(custom_worldviews))\n",
        "            )\n",
        "            for project_id in data\n",
        "        }\n",
        "        best_project = _argmax_project(expected_scores, tie_break=tie_break, rng=rng)\n",
        "        allocations[best_project] = increment\n",
        "\n",
        "        if return_debug:\n",
        "            return allocations, {\n",
        "                \"strategy\": \"custom_worldviews\",\n",
        "                \"expected_scores\": expected_scores,\n",
        "                \"selected_project\": best_project,\n",
        "            }\n",
        "        return allocations\n",
        "\n",
        "    required_legacy = {\n",
        "        \"q1_cred\": q1_cred,\n",
        "        \"q2_cred\": q2_cred,\n",
        "        \"q3_cred\": q3_cred,\n",
        "        \"q4_cred\": q4_cred,\n",
        "        \"q5_cred\": q5_cred,\n",
        "        \"q6_cred\": q6_cred,\n",
        "        \"q7_cred\": q7_cred,\n",
        "        \"q1_daly_weights\": q1_daly_weights,\n",
        "        \"q2_income_weights\": q2_income_weights,\n",
        "        \"q3_chicken_multipliers\": q3_chicken_multipliers,\n",
        "        \"q4_shrimp_multipliers\": q4_shrimp_multipliers,\n",
        "        \"q5_discount_factors\": q5_discount_factors,\n",
        "        \"q7_extinction_probs\": q7_extinction_probs,\n",
        "        \"build_moral_weights_fn\": build_moral_weights_fn,\n",
        "    }\n",
        "    missing = [name for name, value in required_legacy.items() if value is None]\n",
        "    if missing:\n",
        "        raise ValueError(\"vote_mec legacy interface is missing required parameters: \" + \", \".join(missing))\n",
        "\n",
        "    avg_q1 = sum(c * v for c, v in zip(q1_cred, q1_daly_weights))\n",
        "    avg_q2 = sum(c * v for c, v in zip(q2_cred, q2_income_weights))\n",
        "    avg_q3 = sum(c * v for c, v in zip(q3_cred, q3_chicken_multipliers))\n",
        "    avg_q4 = sum(c * v for c, v in zip(q4_cred, q4_shrimp_multipliers))\n",
        "    avg_q5 = [\n",
        "        sum(c * v for c, v in zip(q5_cred, [q5_discount_factors[i][t] for i in range(4)]))\n",
        "        for t in range(6)\n",
        "    ]\n",
        "    avg_q7 = sum(c * v for c, v in zip(q7_cred, q7_extinction_probs))\n",
        "    moral_weights = build_moral_weights_fn(avg_q1, avg_q2, avg_q3, avg_q4)\n",
        "\n",
        "    for risk_idx, risk_credence in enumerate(q6_cred):\n",
        "        if risk_credence == 0:\n",
        "            continue\n",
        "\n",
        "        base_values = calculate_all_projects(data, moral_weights, avg_q5, risk_idx)\n",
        "        adjusted_values = adjust_for_extinction_risk(base_values, data, avg_q7)\n",
        "\n",
        "        marginal_values = {\n",
        "            p: adjusted_values[p] * get_diminishing_returns_factor(data, p, funding[p])\n",
        "            for p in data\n",
        "        }\n",
        "        best_project = _argmax_project(marginal_values, tie_break=tie_break, rng=rng)\n",
        "        allocations[best_project] += risk_credence * increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\"strategy\": \"legacy_quiz_inputs\"}\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_met(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    met_threshold=None,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    threshold = AGGREGATION_DEFAULTS[\"met_threshold\"] if met_threshold is None else met_threshold\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    max_idx = int(np.argmax(credences))\n",
        "    max_credence = credences[max_idx]\n",
        "\n",
        "    strategy = \"favorite_theory\"\n",
        "    selected_idx = max_idx\n",
        "\n",
        "    if max_credence < threshold:\n",
        "\n",
        "        class _WorldviewAdapter:\n",
        "            def __init__(self, scores):\n",
        "                self._scores = scores\n",
        "\n",
        "            def evaluate(self, project_id):\n",
        "                return self._scores[project_id]\n",
        "\n",
        "        projects = list(data.keys())\n",
        "        adapters = [_WorldviewAdapter(scores) for scores in worldview_scores]\n",
        "        pearson_matrix, rank_matrix = calculate_pairwise_similarities(adapters, projects)\n",
        "        positions = embed_worldviews_in_2d_space(pearson_matrix, rank_matrix)\n",
        "        centroid = calculate_weighted_centroid(positions, np.array(credences))\n",
        "        selected_idx = find_closest_worldview(positions, centroid)\n",
        "        strategy = \"similarity_centroid\"\n",
        "\n",
        "    selected_scores = worldview_scores[selected_idx]\n",
        "    best_project = _argmax_project(selected_scores, tie_break=tie_break, rng=rng)\n",
        "    allocations[best_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\n",
        "            \"strategy\": strategy,\n",
        "            \"threshold\": threshold,\n",
        "            \"max_credence\": max_credence,\n",
        "            \"selected_worldview\": custom_worldviews[selected_idx].get(\"name\", f\"worldview_{selected_idx}\"),\n",
        "            \"selected_project\": best_project,\n",
        "        }\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def _nash_disagreement_utilities(worldview_scores, credences, disagreement_point, tie_break=\"deterministic\", rng=None):\n",
        "    n_worldviews = len(worldview_scores)\n",
        "    projects = list(worldview_scores[0].keys()) if worldview_scores else []\n",
        "    best_projects = [_argmax_project(scores, tie_break=tie_break, rng=rng) for scores in worldview_scores]\n",
        "\n",
        "    if disagreement_point == \"zero_spending\":\n",
        "        return [0.0 for _ in range(n_worldviews)]\n",
        "\n",
        "    if disagreement_point == \"anti_utopia\":\n",
        "        return [min(scores[p] for p in projects) for scores in worldview_scores]\n",
        "\n",
        "    if disagreement_point == \"random_dictator\":\n",
        "        utilities = []\n",
        "        for i in range(n_worldviews):\n",
        "            baseline = 0.0\n",
        "            for j in range(n_worldviews):\n",
        "                baseline += credences[j] * worldview_scores[i][best_projects[j]]\n",
        "            utilities.append(baseline)\n",
        "        return utilities\n",
        "\n",
        "    if disagreement_point == \"exclusionary_proportional_split\":\n",
        "        utilities = []\n",
        "        for i in range(n_worldviews):\n",
        "            own_credence = credences[i]\n",
        "            if own_credence >= 1.0:\n",
        "                utilities.append(0.0)\n",
        "                continue\n",
        "            baseline = 0.0\n",
        "            denominator = 1.0 - own_credence\n",
        "            for j in range(n_worldviews):\n",
        "                if j == i:\n",
        "                    continue\n",
        "                baseline += (credences[j] / denominator) * worldview_scores[i][best_projects[j]]\n",
        "            utilities.append(baseline)\n",
        "        return utilities\n",
        "\n",
        "    raise ValueError(\n",
        "        \"Unknown disagreement_point. Use one of: zero_spending, anti_utopia, random_dictator, exclusionary_proportional_split.\"\n",
        "    )\n",
        "\n",
        "\n",
        "def vote_nash_bargaining(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    disagreement_point=None,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    disagreement_point = (\n",
        "        AGGREGATION_DEFAULTS[\"nash_disagreement_point\"]\n",
        "        if disagreement_point is None\n",
        "        else disagreement_point\n",
        "    )\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    projects = list(data.keys())\n",
        "\n",
        "    disagreement_utilities = _nash_disagreement_utilities(\n",
        "        worldview_scores,\n",
        "        credences,\n",
        "        disagreement_point,\n",
        "        tie_break=tie_break,\n",
        "        rng=rng,\n",
        "    )\n",
        "\n",
        "    feasible_scores = {}\n",
        "    fallback_scores = {}\n",
        "    for project_id in projects:\n",
        "        gains = [\n",
        "            worldview_scores[i][project_id] - disagreement_utilities[i]\n",
        "            for i in range(len(custom_worldviews))\n",
        "        ]\n",
        "        if all(g >= -1e-12 for g in gains):\n",
        "            feasible_scores[project_id] = float(np.prod([max(g, 0.0) for g in gains]))\n",
        "        fallback_scores[project_id] = float(sum(gains))\n",
        "\n",
        "    if feasible_scores:\n",
        "        best_value = max(feasible_scores.values())\n",
        "        candidates = [p for p, score in feasible_scores.items() if np.isclose(score, best_value)]\n",
        "        objective_used = \"nash_product\"\n",
        "        objective_scores = feasible_scores\n",
        "    else:\n",
        "        best_value = max(fallback_scores.values())\n",
        "        candidates = [p for p, score in fallback_scores.items() if np.isclose(score, best_value)]\n",
        "        objective_used = \"sum_gains_fallback\"\n",
        "        objective_scores = fallback_scores\n",
        "\n",
        "    selected_project = _choose_from_candidates(candidates, tie_break=tie_break, rng=rng)\n",
        "    allocations[selected_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\n",
        "            \"disagreement_point\": disagreement_point,\n",
        "            \"objective\": objective_used,\n",
        "            \"objective_scores\": objective_scores,\n",
        "            \"disagreement_utilities\": disagreement_utilities,\n",
        "            \"selected_project\": selected_project,\n",
        "        }\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_msa(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    worldview_types=None,\n",
        "    cardinal_permissibility_mode=None,\n",
        "    cardinal_top_k=None,\n",
        "    cardinal_within_percent=None,\n",
        "    binary_permissibility_threshold=None,\n",
        "    no_permissible_action=\"stop\",\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "    cardinal_permissibility_mode = (\n",
        "        AGGREGATION_DEFAULTS[\"msa_permissibility_mode\"]\n",
        "        if cardinal_permissibility_mode is None\n",
        "        else cardinal_permissibility_mode\n",
        "    )\n",
        "    cardinal_top_k = AGGREGATION_DEFAULTS[\"msa_top_k\"] if cardinal_top_k is None else cardinal_top_k\n",
        "    cardinal_within_percent = (\n",
        "        AGGREGATION_DEFAULTS[\"msa_within_percent\"]\n",
        "        if cardinal_within_percent is None\n",
        "        else cardinal_within_percent\n",
        "    )\n",
        "    binary_permissibility_threshold = (\n",
        "        AGGREGATION_DEFAULTS[\"msa_binary_threshold\"]\n",
        "        if binary_permissibility_threshold is None\n",
        "        else binary_permissibility_threshold\n",
        "    )\n",
        "\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    projects = list(data.keys())\n",
        "\n",
        "    cardinal_indices = []\n",
        "    binary_indices = []\n",
        "    for idx, worldview in enumerate(custom_worldviews):\n",
        "        worldview_type = _resolve_msa_worldview_type(worldview, worldview_types=worldview_types)\n",
        "        if worldview_type == \"binary\":\n",
        "            binary_indices.append(idx)\n",
        "        else:\n",
        "            cardinal_indices.append(idx)\n",
        "\n",
        "    cardinal_cluster_credence = sum(credences[idx] for idx in cardinal_indices)\n",
        "    mec_scores = {project_id: 0.0 for project_id in projects}\n",
        "    cardinal_best = None\n",
        "\n",
        "    if cardinal_indices:\n",
        "        cardinal_theories = []\n",
        "        credence_distribution = {}\n",
        "        for idx in cardinal_indices:\n",
        "            name = custom_worldviews[idx].get(\"name\", f\"worldview_{idx}\")\n",
        "            theory_name = f\"{name}_{idx}\"\n",
        "            cardinal_theories.append(MoralTheory(theory_name, worldview_scores[idx]))\n",
        "            credence_distribution[theory_name] = credences[idx]\n",
        "\n",
        "        cardinal_best, mec_scores = mec_aggregate_cardinal_theories(\n",
        "            projects, cardinal_theories, credence_distribution\n",
        "        )\n",
        "\n",
        "    cardinal_permissible = set()\n",
        "    threshold_score = None\n",
        "    if cardinal_indices:\n",
        "        if cardinal_permissibility_mode == \"winner_take_all\":\n",
        "            cardinal_permissible = {cardinal_best}\n",
        "        elif cardinal_permissibility_mode == \"top_k\":\n",
        "            k = max(1, int(cardinal_top_k))\n",
        "            ranked = sorted(projects, key=lambda p: (-mec_scores[p], p))\n",
        "            cardinal_permissible = set(ranked[: min(k, len(ranked))])\n",
        "        elif cardinal_permissibility_mode == \"within_percent\":\n",
        "            if cardinal_within_percent < 0:\n",
        "                raise ValueError(\"cardinal_within_percent must be >= 0.\")\n",
        "            best_score = mec_scores[cardinal_best]\n",
        "            threshold_score = best_score - abs(best_score) * float(cardinal_within_percent)\n",
        "            cardinal_permissible = {\n",
        "                p for p in projects if mec_scores[p] >= threshold_score - 1e-12\n",
        "            }\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Unknown cardinal_permissibility_mode. Use one of: winner_take_all, top_k, within_percent.\"\n",
        "            )\n",
        "\n",
        "    vote_tallies = {project_id: 0.0 for project_id in projects}\n",
        "\n",
        "    for project_id in cardinal_permissible:\n",
        "        vote_tallies[project_id] += cardinal_cluster_credence\n",
        "\n",
        "    for idx in binary_indices:\n",
        "        worldview_credence = credences[idx]\n",
        "        scores = worldview_scores[idx]\n",
        "        for project_id in projects:\n",
        "            if scores[project_id] > binary_permissibility_threshold:\n",
        "                vote_tallies[project_id] += worldview_credence\n",
        "\n",
        "    max_tally = max(vote_tallies.values()) if vote_tallies else 0.0\n",
        "    if max_tally <= 0.5:\n",
        "        if no_permissible_action == \"stop\":\n",
        "            stop_signal = {\n",
        "                \"__stop__\": True,\n",
        "                \"__reason__\": \"No intervention exceeded 50% permissibility.\",\n",
        "            }\n",
        "            debug = {\n",
        "                \"vote_tallies\": vote_tallies,\n",
        "                \"mec_scores\": mec_scores,\n",
        "                \"cardinal_permissible\": sorted(cardinal_permissible),\n",
        "            }\n",
        "            return (stop_signal, debug) if return_debug else stop_signal\n",
        "\n",
        "        if no_permissible_action == \"fallback_mec\":\n",
        "            if cardinal_indices:\n",
        "                selected_project = _argmax_project(mec_scores, tie_break=tie_break, rng=rng)\n",
        "            else:\n",
        "                weighted_scores = {\n",
        "                    project_id: sum(\n",
        "                        credences[idx] * worldview_scores[idx][project_id]\n",
        "                        for idx in range(len(custom_worldviews))\n",
        "                    )\n",
        "                    for project_id in projects\n",
        "                }\n",
        "                selected_project = _argmax_project(weighted_scores, tie_break=tie_break, rng=rng)\n",
        "            allocations[selected_project] = increment\n",
        "            if return_debug:\n",
        "                return allocations, {\n",
        "                    \"fallback_used\": True,\n",
        "                    \"selected_project\": selected_project,\n",
        "                    \"vote_tallies\": vote_tallies,\n",
        "                    \"mec_scores\": mec_scores,\n",
        "                }\n",
        "            return allocations\n",
        "\n",
        "        raise ValueError(\"Unknown no_permissible_action. Use stop or fallback_mec.\")\n",
        "\n",
        "    winners = [project_id for project_id, tally in vote_tallies.items() if np.isclose(tally, max_tally)]\n",
        "    selected_project = _choose_from_candidates(winners, tie_break=tie_break, rng=rng)\n",
        "    allocations[selected_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\n",
        "            \"selected_project\": selected_project,\n",
        "            \"vote_tallies\": vote_tallies,\n",
        "            \"mec_scores\": mec_scores,\n",
        "            \"cardinal_permissible\": sorted(cardinal_permissible),\n",
        "            \"cardinal_permissibility_mode\": cardinal_permissibility_mode,\n",
        "            \"threshold_score\": threshold_score,\n",
        "        }\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_borda(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    projects = list(data.keys())\n",
        "    n_projects = len(projects)\n",
        "\n",
        "    borda_scores = {project_id: 0.0 for project_id in projects}\n",
        "    for idx, scores in enumerate(worldview_scores):\n",
        "        ranking = _build_project_ranking(scores)\n",
        "        for rank_idx, project_id in enumerate(ranking):\n",
        "            points = (n_projects - 1) - rank_idx\n",
        "            borda_scores[project_id] += credences[idx] * points\n",
        "\n",
        "    best_value = max(borda_scores.values())\n",
        "    winners = [project_id for project_id, score in borda_scores.items() if np.isclose(score, best_value)]\n",
        "    selected_project = _choose_from_candidates(winners, tie_break=tie_break, rng=rng)\n",
        "    allocations[selected_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\"borda_scores\": borda_scores, \"selected_project\": selected_project}\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_split_cycle(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    projects = list(data.keys())\n",
        "\n",
        "    preferences = {a: {b: 0.0 for b in projects} for a in projects}\n",
        "\n",
        "    for idx, scores in enumerate(worldview_scores):\n",
        "        weight = credences[idx]\n",
        "        for i, project_a in enumerate(projects):\n",
        "            for j in range(i + 1, len(projects)):\n",
        "                project_b = projects[j]\n",
        "                if scores[project_a] > scores[project_b]:\n",
        "                    preferences[project_a][project_b] += weight\n",
        "                elif scores[project_b] > scores[project_a]:\n",
        "                    preferences[project_b][project_a] += weight\n",
        "\n",
        "    margins = {\n",
        "        a: {b: preferences[a][b] - preferences[b][a] for b in projects}\n",
        "        for a in projects\n",
        "    }\n",
        "\n",
        "    neg_inf = float(\"-inf\")\n",
        "    strongest_path = {\n",
        "        a: {b: (margins[a][b] if margins[a][b] > 0 else neg_inf) for b in projects}\n",
        "        for a in projects\n",
        "    }\n",
        "    for p in projects:\n",
        "        strongest_path[p][p] = 0.0\n",
        "\n",
        "    for k in projects:\n",
        "        for i in projects:\n",
        "            if i == k:\n",
        "                continue\n",
        "            for j in projects:\n",
        "                if i == j or j == k:\n",
        "                    continue\n",
        "                via_k = min(strongest_path[i][k], strongest_path[k][j])\n",
        "                if via_k > strongest_path[i][j]:\n",
        "                    strongest_path[i][j] = via_k\n",
        "\n",
        "    defeats = {\n",
        "        a: {\n",
        "            b: (margins[a][b] > 0 and margins[a][b] > strongest_path[b][a] + 1e-12)\n",
        "            for b in projects\n",
        "        }\n",
        "        for a in projects\n",
        "    }\n",
        "\n",
        "    unbeaten = [\n",
        "        candidate\n",
        "        for candidate in projects\n",
        "        if not any(defeats[other][candidate] for other in projects if other != candidate)\n",
        "    ]\n",
        "\n",
        "    if unbeaten:\n",
        "        winners = unbeaten\n",
        "    else:\n",
        "        net_scores = {\n",
        "            candidate: sum(margins[candidate][other] for other in projects if other != candidate)\n",
        "            for candidate in projects\n",
        "        }\n",
        "        best_net = max(net_scores.values())\n",
        "        winners = [p for p, score in net_scores.items() if np.isclose(score, best_net)]\n",
        "\n",
        "    selected_project = _choose_from_candidates(winners, tie_break=tie_break, rng=rng)\n",
        "    allocations[selected_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\n",
        "            \"margins\": margins,\n",
        "            \"strongest_path\": strongest_path,\n",
        "            \"defeats\": defeats,\n",
        "            \"selected_project\": selected_project,\n",
        "        }\n",
        "    return allocations\n",
        "\n",
        "\n",
        "def vote_lexicographic_maximin(\n",
        "    data,\n",
        "    funding,\n",
        "    increment,\n",
        "    custom_worldviews,\n",
        "    tie_break=None,\n",
        "    random_seed=None,\n",
        "    return_debug=False,\n",
        "):\n",
        "    allocations = {p: 0 for p in data}\n",
        "    if not custom_worldviews:\n",
        "        return (allocations, {\"strategy\": \"no_worldviews\"}) if return_debug else allocations\n",
        "\n",
        "    tie_break = AGGREGATION_DEFAULTS[\"tie_break\"] if tie_break is None else tie_break\n",
        "    rng = _build_rng(tie_break, random_seed)\n",
        "    worldview_scores = _compute_all_worldview_marginal_values(data, funding, custom_worldviews)\n",
        "    credences = _normalize_credences(custom_worldviews)\n",
        "    projects = list(data.keys())\n",
        "\n",
        "    vectors = {}\n",
        "    for project_id in projects:\n",
        "        weighted_utilities = [\n",
        "            credences[idx] * worldview_scores[idx][project_id]\n",
        "            for idx in range(len(custom_worldviews))\n",
        "        ]\n",
        "        vectors[project_id] = tuple(sorted(weighted_utilities))\n",
        "\n",
        "    best_vector = max(vectors.values())\n",
        "    winners = [project_id for project_id, vector in vectors.items() if vector == best_vector]\n",
        "    selected_project = _choose_from_candidates(winners, tie_break=tie_break, rng=rng)\n",
        "    allocations[selected_project] = increment\n",
        "\n",
        "    if return_debug:\n",
        "        return allocations, {\"vectors\": vectors, \"selected_project\": selected_project}\n",
        "    return allocations\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Iteration loop and display helpers\n",
        "# -----------------------------------------------------------------------------\n",
        "def allocate_budget(data, voting_method, total_budget, increment_size=None, **kwargs):\n",
        "    if increment_size is None:\n",
        "        increment_size = INCREMENT_SIZE\n",
        "\n",
        "    funding = {project_id: 0 for project_id in data}\n",
        "    history = []\n",
        "    remaining = total_budget\n",
        "\n",
        "    while remaining > 0:\n",
        "        increment = min(increment_size, remaining)\n",
        "        vote_output = voting_method(data, funding, increment, **kwargs)\n",
        "\n",
        "        metadata = {}\n",
        "        if (\n",
        "            isinstance(vote_output, tuple)\n",
        "            and len(vote_output) == 2\n",
        "            and isinstance(vote_output[0], dict)\n",
        "        ):\n",
        "            allocations, metadata = vote_output\n",
        "            if not isinstance(metadata, dict):\n",
        "                metadata = {\"raw_metadata\": metadata}\n",
        "        else:\n",
        "            allocations = vote_output\n",
        "\n",
        "        if not isinstance(allocations, dict):\n",
        "            raise TypeError(\"Voting methods must return a dict of allocations.\")\n",
        "\n",
        "        if allocations.get(\"__stop__\", False):\n",
        "            stop_entry = {\n",
        "                \"iteration\": len(history),\n",
        "                \"allocations\": {project_id: 0 for project_id in data},\n",
        "                \"stopped\": True,\n",
        "                \"remaining_budget\": remaining,\n",
        "            }\n",
        "            if \"__reason__\" in allocations:\n",
        "                stop_entry[\"reason\"] = allocations[\"__reason__\"]\n",
        "            if metadata:\n",
        "                stop_entry[\"meta\"] = metadata\n",
        "            history.append(stop_entry)\n",
        "            break\n",
        "\n",
        "        for project_id in data:\n",
        "            funding[project_id] += allocations.get(project_id, 0)\n",
        "\n",
        "        history_entry = {\n",
        "            \"iteration\": len(history),\n",
        "            \"allocations\": {project_id: allocations.get(project_id, 0) for project_id in data},\n",
        "        }\n",
        "        if metadata:\n",
        "            history_entry[\"meta\"] = metadata\n",
        "        history.append(history_entry)\n",
        "        remaining -= increment\n",
        "\n",
        "    return {\"funding\": funding, \"history\": history}\n",
        "\n",
        "\n",
        "def show_allocation(allocation, data):\n",
        "    funding = allocation[\"funding\"]\n",
        "    total = sum(funding.values())\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"BUDGET ALLOCATION (total: ${total:,.1f}M)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"{'Project':<24} {'Allocated':>10} {'% budget':>10}\")\n",
        "    print(\"-\" * 60)\n",
        "    for project_id, amount in sorted(funding.items(), key=lambda x: x[1], reverse=True):\n",
        "        pct = (amount / total * 100) if total > 0 else 0\n",
        "        print(f\"{project_id:<24} ${amount:>7.1f}M {pct:>8.1f}%\")\n",
        "\n",
        "\n",
        "def funding_dataframe(allocation):\n",
        "    funding = allocation[\"funding\"]\n",
        "    total = sum(funding.values())\n",
        "    rows = []\n",
        "    for project_id, amount in sorted(funding.items(), key=lambda x: x[1], reverse=True):\n",
        "        rows.append(\n",
        "            {\n",
        "                \"project_id\": project_id,\n",
        "                \"funding\": amount,\n",
        "                \"percent\": (amount / total * 100) if total > 0 else 0.0,\n",
        "            }\n",
        "        )\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def _show_df(df):\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "\n",
        "        display(df)\n",
        "    except Exception:\n",
        "        print(df.to_string(index=False))\n",
        "\n",
        "\n",
        "METHOD_REGISTRY = {\n",
        "    \"credence_weighted\": vote_credence_weighted_custom,\n",
        "    \"my_favorite_theory\": vote_my_favorite_theory,\n",
        "    \"mec\": vote_mec,\n",
        "    \"met\": vote_met,\n",
        "    \"nash_bargaining\": vote_nash_bargaining,\n",
        "    \"msa\": vote_msa,\n",
        "    \"borda\": vote_borda,\n",
        "    \"split_cycle\": vote_split_cycle,\n",
        "    \"lexicographic_maximin\": vote_lexicographic_maximin,\n",
        "}\n",
        "\n",
        "print(\"Loaded standalone Donor Compass snapshot.\")\n",
        "print(\"Available methods:\", list(METHOD_REGISTRY.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57975164",
      "metadata": {},
      "source": [
        "## Demo Run (Single Method)\n",
        "\n",
        "Edit `SELECTED_METHOD`, budget, and method-specific options in the next cell, then run the execution cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "408ef5a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected method: credence_weighted\n",
            "Available methods: ['credence_weighted', 'my_favorite_theory', 'mec', 'met', 'nash_bargaining', 'msa', 'borda', 'split_cycle', 'lexicographic_maximin']\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# Core run settings\n",
        "SELECTED_METHOD = \"credence_weighted\"  # change to any key in METHOD_REGISTRY\n",
        "TOTAL_BUDGET = 100\n",
        "INCREMENT_SIZE = 10\n",
        "\n",
        "# Start from example worldviews and edit values as desired\n",
        "CUSTOM_WORLDVIEWS = deepcopy(EXAMPLE_CUSTOM_WORLDVIEWS)\n",
        "\n",
        "# Global tie settings for methods that support it\n",
        "TIE_BREAK = \"deterministic\"  # deterministic | random\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Method-specific settings\n",
        "MET_THRESHOLD = 0.50\n",
        "NASH_DISAGREEMENT_POINT = \"zero_spending\"  # zero_spending | anti_utopia | random_dictator | exclusionary_proportional_split\n",
        "MSA_CARDINAL_MODE = \"winner_take_all\"      # winner_take_all | top_k | within_percent\n",
        "MSA_TOP_K = 2\n",
        "MSA_WITHIN_PERCENT = 0.10\n",
        "MSA_BINARY_THRESHOLD = 0.0\n",
        "MSA_NO_PERMISSIBLE_ACTION = \"fallback_mec\" # stop | fallback_mec\n",
        "\n",
        "\n",
        "def build_method_kwargs(method_name, custom_worldviews):\n",
        "    kwargs = {\"custom_worldviews\": custom_worldviews}\n",
        "\n",
        "    if method_name == \"met\":\n",
        "        kwargs.update({\n",
        "            \"met_threshold\": MET_THRESHOLD,\n",
        "            \"tie_break\": TIE_BREAK,\n",
        "            \"random_seed\": RANDOM_SEED,\n",
        "        })\n",
        "    elif method_name == \"nash_bargaining\":\n",
        "        kwargs.update({\n",
        "            \"disagreement_point\": NASH_DISAGREEMENT_POINT,\n",
        "            \"tie_break\": TIE_BREAK,\n",
        "            \"random_seed\": RANDOM_SEED,\n",
        "        })\n",
        "    elif method_name == \"msa\":\n",
        "        kwargs.update({\n",
        "            \"cardinal_permissibility_mode\": MSA_CARDINAL_MODE,\n",
        "            \"cardinal_top_k\": MSA_TOP_K,\n",
        "            \"cardinal_within_percent\": MSA_WITHIN_PERCENT,\n",
        "            \"binary_permissibility_threshold\": MSA_BINARY_THRESHOLD,\n",
        "            \"no_permissible_action\": MSA_NO_PERMISSIBLE_ACTION,\n",
        "            \"tie_break\": TIE_BREAK,\n",
        "            \"random_seed\": RANDOM_SEED,\n",
        "        })\n",
        "    elif method_name in {\n",
        "        \"my_favorite_theory\",\n",
        "        \"mec\",\n",
        "        \"borda\",\n",
        "        \"split_cycle\",\n",
        "        \"lexicographic_maximin\",\n",
        "    }:\n",
        "        kwargs.update({\"tie_break\": TIE_BREAK, \"random_seed\": RANDOM_SEED})\n",
        "\n",
        "    return kwargs\n",
        "\n",
        "\n",
        "print(\"Selected method:\", SELECTED_METHOD)\n",
        "print(\"Available methods:\", list(METHOD_REGISTRY.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f2c458b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "BUDGET ALLOCATION (total: $100.0M)\n",
            "============================================================\n",
            "Project                   Allocated   % budget\n",
            "------------------------------------------------------------\n",
            "project_human            $   50.0M     50.0%\n",
            "project_chicken          $   30.0M     30.0%\n",
            "project_fish             $   20.0M     20.0%\n",
            "\n",
            "Funding table:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>project_id</th>\n",
              "      <th>funding</th>\n",
              "      <th>percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>project_human</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>project_chicken</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>project_fish</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        project_id  funding  percent\n",
              "0    project_human     50.0     50.0\n",
              "1  project_chicken     30.0     30.0\n",
              "2     project_fish     20.0     20.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "History preview (first 5 iterations):\n",
            "{'iteration': 0, 'allocations': {'project_human': 5.0, 'project_chicken': 3.0, 'project_fish': 2.0}}\n",
            "{'iteration': 1, 'allocations': {'project_human': 5.0, 'project_chicken': 3.0, 'project_fish': 2.0}}\n",
            "{'iteration': 2, 'allocations': {'project_human': 5.0, 'project_chicken': 3.0, 'project_fish': 2.0}}\n",
            "{'iteration': 3, 'allocations': {'project_human': 5.0, 'project_chicken': 3.0, 'project_fish': 2.0}}\n",
            "{'iteration': 4, 'allocations': {'project_human': 5.0, 'project_chicken': 3.0, 'project_fish': 2.0}}\n"
          ]
        }
      ],
      "source": [
        "# Run the selected method\n",
        "if SELECTED_METHOD not in METHOD_REGISTRY:\n",
        "    raise ValueError(f\"Unknown method: {SELECTED_METHOD}\")\n",
        "\n",
        "method_fn = METHOD_REGISTRY[SELECTED_METHOD]\n",
        "method_kwargs = build_method_kwargs(SELECTED_METHOD, deepcopy(CUSTOM_WORLDVIEWS))\n",
        "\n",
        "allocation = allocate_budget(\n",
        "    DEFAULT_PROJECT_DATA,\n",
        "    method_fn,\n",
        "    total_budget=TOTAL_BUDGET,\n",
        "    increment_size=INCREMENT_SIZE,\n",
        "    **method_kwargs,\n",
        ")\n",
        "\n",
        "show_allocation(allocation, DEFAULT_PROJECT_DATA)\n",
        "\n",
        "print(\"\\nFunding table:\")\n",
        "_show_df(funding_dataframe(allocation))\n",
        "\n",
        "if allocation[\"history\"] and allocation[\"history\"][-1].get(\"stopped\"):\n",
        "    last = allocation[\"history\"][-1]\n",
        "    print(\"\\nAllocation stopped early.\")\n",
        "    print(\"Reason:\", last.get(\"reason\"))\n",
        "    print(\"Remaining budget:\", last.get(\"remaining_budget\"))\n",
        "\n",
        "print(\"\\nHistory preview (first 5 iterations):\")\n",
        "for entry in allocation[\"history\"][:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb99380",
      "metadata": {},
      "source": [
        "## Compare All Methods On The Same Inputs\n",
        "\n",
        "This runs every aggregation method with the same worldviews and budget, then reports top project and concentration (HHI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "99b78904",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>top_project</th>\n",
              "      <th>hhi</th>\n",
              "      <th>funding</th>\n",
              "      <th>stopped_early</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>credence_weighted</td>\n",
              "      <td>project_human</td>\n",
              "      <td>0.38</td>\n",
              "      <td>{'project_human': 50.0, 'project_chicken': 30....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nash_bargaining</td>\n",
              "      <td>project_chicken</td>\n",
              "      <td>0.38</td>\n",
              "      <td>{'project_human': 20, 'project_chicken': 50, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lexicographic_maximin</td>\n",
              "      <td>project_fish</td>\n",
              "      <td>0.38</td>\n",
              "      <td>{'project_human': 20, 'project_chicken': 30, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mec</td>\n",
              "      <td>project_chicken</td>\n",
              "      <td>0.52</td>\n",
              "      <td>{'project_human': 40, 'project_chicken': 60, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>msa</td>\n",
              "      <td>project_chicken</td>\n",
              "      <td>0.52</td>\n",
              "      <td>{'project_human': 40, 'project_chicken': 60, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>borda</td>\n",
              "      <td>project_chicken</td>\n",
              "      <td>0.58</td>\n",
              "      <td>{'project_human': 30, 'project_chicken': 70, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>split_cycle</td>\n",
              "      <td>project_chicken</td>\n",
              "      <td>0.58</td>\n",
              "      <td>{'project_human': 30, 'project_chicken': 70, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my_favorite_theory</td>\n",
              "      <td>project_human</td>\n",
              "      <td>1.00</td>\n",
              "      <td>{'project_human': 100, 'project_chicken': 0, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>met</td>\n",
              "      <td>project_human</td>\n",
              "      <td>1.00</td>\n",
              "      <td>{'project_human': 100, 'project_chicken': 0, '...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  method      top_project   hhi  \\\n",
              "0      credence_weighted    project_human  0.38   \n",
              "4        nash_bargaining  project_chicken  0.38   \n",
              "8  lexicographic_maximin     project_fish  0.38   \n",
              "2                    mec  project_chicken  0.52   \n",
              "5                    msa  project_chicken  0.52   \n",
              "6                  borda  project_chicken  0.58   \n",
              "7            split_cycle  project_chicken  0.58   \n",
              "1     my_favorite_theory    project_human  1.00   \n",
              "3                    met    project_human  1.00   \n",
              "\n",
              "                                             funding  stopped_early  \n",
              "0  {'project_human': 50.0, 'project_chicken': 30....          False  \n",
              "4  {'project_human': 20, 'project_chicken': 50, '...          False  \n",
              "8  {'project_human': 20, 'project_chicken': 30, '...          False  \n",
              "2  {'project_human': 40, 'project_chicken': 60, '...          False  \n",
              "5  {'project_human': 40, 'project_chicken': 60, '...          False  \n",
              "6  {'project_human': 30, 'project_chicken': 70, '...          False  \n",
              "7  {'project_human': 30, 'project_chicken': 70, '...          False  \n",
              "1  {'project_human': 100, 'project_chicken': 0, '...          False  \n",
              "3  {'project_human': 100, 'project_chicken': 0, '...          False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Funding by method:\n",
            "- credence_weighted: {'project_human': 50.0, 'project_chicken': 30.0, 'project_fish': 20.0}\n",
            "- my_favorite_theory: {'project_human': 100, 'project_chicken': 0, 'project_fish': 0}\n",
            "- mec: {'project_human': 40, 'project_chicken': 60, 'project_fish': 0}\n",
            "- met: {'project_human': 100, 'project_chicken': 0, 'project_fish': 0}\n",
            "- nash_bargaining: {'project_human': 20, 'project_chicken': 50, 'project_fish': 30}\n",
            "- msa: {'project_human': 40, 'project_chicken': 60, 'project_fish': 0}\n",
            "- borda: {'project_human': 30, 'project_chicken': 70, 'project_fish': 0}\n",
            "- split_cycle: {'project_human': 30, 'project_chicken': 70, 'project_fish': 0}\n",
            "- lexicographic_maximin: {'project_human': 20, 'project_chicken': 30, 'project_fish': 50}\n"
          ]
        }
      ],
      "source": [
        "comparison_rows = []\n",
        "for method_name, method_fn in METHOD_REGISTRY.items():\n",
        "    kwargs = build_method_kwargs(method_name, deepcopy(CUSTOM_WORLDVIEWS))\n",
        "    result = allocate_budget(\n",
        "        DEFAULT_PROJECT_DATA,\n",
        "        method_fn,\n",
        "        total_budget=TOTAL_BUDGET,\n",
        "        increment_size=INCREMENT_SIZE,\n",
        "        **kwargs,\n",
        "    )\n",
        "    funding = result[\"funding\"]\n",
        "    top_project = max(funding, key=funding.get)\n",
        "    comparison_rows.append(\n",
        "        {\n",
        "            \"method\": method_name,\n",
        "            \"top_project\": top_project,\n",
        "            \"hhi\": _hhi(funding),\n",
        "            \"funding\": funding,\n",
        "            \"stopped_early\": bool(result[\"history\"] and result[\"history\"][-1].get(\"stopped\")),\n",
        "        }\n",
        "    )\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_rows).sort_values(\"hhi\")\n",
        "_show_df(comparison_df)\n",
        "\n",
        "print(\"\\nFunding by method:\")\n",
        "for row in comparison_rows:\n",
        "    print(f\"- {row['method']}: {row['funding']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7466039",
      "metadata": {},
      "source": [
        "## End-To-End Validation Checks\n",
        "\n",
        "These are the only verification checks included here (no full unit-test suite).\n",
        "\n",
        "- **Check 1: Dominant Then Saturating Project**\n",
        "  - Starts with one project clearly best at first.\n",
        "  - As diminishing returns kick in, methods should eventually switch away from that project.\n",
        "- **Check 2: Same Credences Across Methods**\n",
        "  - Runs every method on the same worldview credences and project inputs.\n",
        "  - Lets you compare how concentrated/diversified each method's allocation is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1d2f0a3d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "AGGREGATION STRESS TEST SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Check 1: Dominant project -> saturation switch\n",
            "--------------------------------------------------------------------------------\n",
            "credence_weighted        | switch_iter=1  | funding={'project_dominant': 10.0, 'project_b': 50.0, 'project_c': 0}\n",
            "my_favorite_theory       | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "mec                      | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "met                      | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "nash_bargaining          | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "msa                      | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "borda                    | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "split_cycle              | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "lexicographic_maximin    | switch_iter=1  | funding={'project_dominant': 10, 'project_b': 50, 'project_c': 0}\n",
            "\n",
            "Check 2: Same credences, all methods side-by-side\n",
            "--------------------------------------------------------------------------------\n",
            "credence_weighted        | top=project_human   | HHI=0.3800 | funding={'project_human': 50.0, 'project_chicken': 30.0, 'project_fish': 20.0}\n",
            "my_favorite_theory       | top=project_human   | HHI=1.0000 | funding={'project_human': 100, 'project_chicken': 0, 'project_fish': 0}\n",
            "mec                      | top=project_chicken | HHI=0.5800 | funding={'project_human': 30, 'project_chicken': 70, 'project_fish': 0}\n",
            "met                      | top=project_human   | HHI=1.0000 | funding={'project_human': 100, 'project_chicken': 0, 'project_fish': 0}\n",
            "nash_bargaining          | top=project_chicken | HHI=0.8200 | funding={'project_human': 10, 'project_chicken': 90, 'project_fish': 0}\n",
            "msa                      | top=project_chicken | HHI=0.5800 | funding={'project_human': 30, 'project_chicken': 70, 'project_fish': 0}\n",
            "borda                    | top=project_chicken | HHI=0.8200 | funding={'project_human': 10, 'project_chicken': 90, 'project_fish': 0}\n",
            "split_cycle              | top=project_chicken | HHI=0.8200 | funding={'project_human': 10, 'project_chicken': 90, 'project_fish': 0}\n",
            "lexicographic_maximin    | top=project_chicken | HHI=0.8200 | funding={'project_human': 10, 'project_chicken': 90, 'project_fish': 0}\n",
            "\n",
            "Expected ordering validated: HHI(credence_weighted) < HHI(mec) < HHI(my_favorite_theory)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def _make_project(recipient_type, base_value, dr_curve):\n",
        "    return {\n",
        "        \"tags\": {\"near_term_xrisk\": False},\n",
        "        \"diminishing_returns\": dr_curve,\n",
        "        \"effects\": {\n",
        "            \"effect_main\": {\n",
        "                \"recipient_type\": recipient_type,\n",
        "                \"values\": [[base_value] * 4 for _ in range(6)],\n",
        "            }\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "def _worldview(name, credence, human=0.0, chickens=0.0, fish=0.0):\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"credence\": credence,\n",
        "        \"moral_weights\": {\n",
        "            \"human_life_years\": human,\n",
        "            \"human_ylds\": 0.0,\n",
        "            \"human_income_doublings\": 0.0,\n",
        "            \"chickens_birds\": chickens,\n",
        "            \"fish\": fish,\n",
        "            \"shrimp\": 0.0,\n",
        "            \"non_shrimp_invertebrates\": 0.0,\n",
        "            \"mammals\": 0.0,\n",
        "        },\n",
        "        \"discount_factors\": [1.0] * 6,\n",
        "        \"risk_profile\": 0,\n",
        "        \"p_extinction\": 0.0,\n",
        "    }\n",
        "\n",
        "\n",
        "def _find_first_switch_iteration(history, dominant_project):\n",
        "    for idx, entry in enumerate(history[1:], start=1):\n",
        "        dominant_allocation = entry[\"allocations\"].get(dominant_project, 0.0)\n",
        "        other_allocation = sum(\n",
        "            amount for project_id, amount in entry[\"allocations\"].items() if project_id != dominant_project\n",
        "        )\n",
        "        if dominant_allocation < 10.0 and other_allocation > 0:\n",
        "            return idx\n",
        "    return None\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Check 1: one dominant project should win early,\n",
        "# then eventually lose once diminishing returns saturate it.\n",
        "# -----------------------------------------------------------------------------\n",
        "dominance_data = {\n",
        "    \"project_dominant\": _make_project(\"human_life_years\", 500.0, [1.0, 0.05, 0.01, 0.01, 0.01, 0.01]),\n",
        "    \"project_b\": _make_project(\"chickens_birds\", 120.0, [1.0] * 6),\n",
        "    \"project_c\": _make_project(\"fish\", 100.0, [1.0] * 6),\n",
        "}\n",
        "aligned_worldviews = [_worldview(\"Aligned\", 1.0, human=1.0, chickens=1.0, fish=1.0)]\n",
        "\n",
        "scenario_a_rows = []\n",
        "for method_name, method_fn in METHOD_REGISTRY.items():\n",
        "    kwargs = {\"custom_worldviews\": aligned_worldviews}\n",
        "    if method_name == \"met\":\n",
        "        kwargs[\"met_threshold\"] = 0.5\n",
        "    if method_name == \"nash_bargaining\":\n",
        "        kwargs[\"disagreement_point\"] = \"zero_spending\"\n",
        "    if method_name == \"msa\":\n",
        "        kwargs.update(\n",
        "            {\n",
        "                \"cardinal_permissibility_mode\": \"winner_take_all\",\n",
        "                \"no_permissible_action\": \"fallback_mec\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    result = allocate_budget(\n",
        "        dominance_data,\n",
        "        method_fn,\n",
        "        total_budget=60,\n",
        "        increment_size=10,\n",
        "        **kwargs,\n",
        "    )\n",
        "    history = result[\"history\"]\n",
        "    first_alloc = history[0][\"allocations\"]\n",
        "\n",
        "    assert first_alloc[\"project_dominant\"] > 0, (\n",
        "        f\"{method_name} failed dominant first-choice check: {first_alloc}\"\n",
        "    )\n",
        "\n",
        "    switch_iter = _find_first_switch_iteration(history, \"project_dominant\")\n",
        "    assert switch_iter is not None, (\n",
        "        f\"{method_name} did not switch after saturation. History: {history}\"\n",
        "    )\n",
        "\n",
        "    non_dominant_total = result[\"funding\"][\"project_b\"] + result[\"funding\"][\"project_c\"]\n",
        "    assert non_dominant_total > 0, (\n",
        "        f\"{method_name} never allocated to alternatives. Funding: {result['funding']}\"\n",
        "    )\n",
        "\n",
        "    scenario_a_rows.append((method_name, switch_iter, dict(result[\"funding\"])))\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Check 2: run all methods with identical credences\n",
        "# and compare concentration/diversification behavior side-by-side.\n",
        "# -----------------------------------------------------------------------------\n",
        "comparison_data = {\n",
        "    \"project_human\": _make_project(\n",
        "        \"human_life_years\",\n",
        "        220.0,\n",
        "        [1.0, 0.8, 0.6, 0.5, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.12],\n",
        "    ),\n",
        "    \"project_chicken\": _make_project(\"chickens_birds\", 180.0, [1.0] * 11),\n",
        "    \"project_fish\": _make_project(\"fish\", 140.0, [1.0] * 11),\n",
        "}\n",
        "shared_worldviews = [\n",
        "    _worldview(\"HumanAnchor\", 0.5, human=1.0, chickens=0.1, fish=0.05),\n",
        "    _worldview(\"ChickenAnchor\", 0.3, human=0.1, chickens=1.0, fish=0.2),\n",
        "    _worldview(\"FishAnchor\", 0.2, human=0.1, chickens=0.1, fish=1.0),\n",
        "]\n",
        "\n",
        "scenario_b_rows = []\n",
        "scenario_b_by_name = {}\n",
        "\n",
        "for method_name, method_fn in METHOD_REGISTRY.items():\n",
        "    kwargs = {\"custom_worldviews\": shared_worldviews}\n",
        "    if method_name == \"met\":\n",
        "        kwargs[\"met_threshold\"] = 0.5\n",
        "    if method_name == \"nash_bargaining\":\n",
        "        kwargs[\"disagreement_point\"] = \"zero_spending\"\n",
        "    if method_name == \"msa\":\n",
        "        kwargs.update(\n",
        "            {\n",
        "                \"cardinal_permissibility_mode\": \"winner_take_all\",\n",
        "                \"no_permissible_action\": \"fallback_mec\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    result = allocate_budget(\n",
        "        comparison_data,\n",
        "        method_fn,\n",
        "        total_budget=100,\n",
        "        increment_size=10,\n",
        "        **kwargs,\n",
        "    )\n",
        "    funding = result[\"funding\"]\n",
        "    row = {\n",
        "        \"method_name\": method_name,\n",
        "        \"funding\": dict(funding),\n",
        "        \"hhi\": _hhi(funding),\n",
        "        \"top_project\": max(funding, key=funding.get),\n",
        "    }\n",
        "    scenario_b_rows.append(row)\n",
        "    scenario_b_by_name[method_name] = row\n",
        "\n",
        "hhi_cw = scenario_b_by_name[\"credence_weighted\"][\"hhi\"]\n",
        "hhi_mec = scenario_b_by_name[\"mec\"][\"hhi\"]\n",
        "hhi_favorite = scenario_b_by_name[\"my_favorite_theory\"][\"hhi\"]\n",
        "assert hhi_cw < hhi_mec < hhi_favorite, (\n",
        "    \"Expected concentration ordering failed: \"\n",
        "    f\"cw={hhi_cw:.4f}, mec={hhi_mec:.4f}, favorite={hhi_favorite:.4f}\"\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Summary print\n",
        "# -----------------------------------------------------------------------------\n",
        "lines = []\n",
        "lines.append(\"=\" * 80)\n",
        "lines.append(\"AGGREGATION STRESS TEST SUMMARY\")\n",
        "lines.append(\"=\" * 80)\n",
        "lines.append(\"\")\n",
        "lines.append(\"Check 1: Dominant project -> saturation switch\")\n",
        "lines.append(\"-\" * 80)\n",
        "for method_name, switch_iter, funding in scenario_a_rows:\n",
        "    lines.append(f\"{method_name:<24} | switch_iter={switch_iter:<2} | funding={funding}\")\n",
        "\n",
        "lines.append(\"\")\n",
        "lines.append(\"Check 2: Same credences, all methods side-by-side\")\n",
        "lines.append(\"-\" * 80)\n",
        "for row in scenario_b_rows:\n",
        "    lines.append(\n",
        "        f\"{row['method_name']:<24} | top={row['top_project']:<15} | \"\n",
        "        f\"HHI={row['hhi']:.4f} | funding={row['funding']}\"\n",
        "    )\n",
        "lines.append(\"\")\n",
        "lines.append(\"Expected ordering validated: HHI(credence_weighted) < HHI(mec) < HHI(my_favorite_theory)\")\n",
        "lines.append(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"\\n\".join(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f73754",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
